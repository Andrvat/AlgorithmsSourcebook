# Contents

- Сортировки
    - [Понятие сортировки. Быстрая сортировка Хоара. Оценка числа операций](#Быстрая-сортировка-Хоара)
    - [Понятие сортировки. Пирамидальная сортировка. Оценка числа операций.](#Пирамидальная-сортировка)
    - [Понятие сортировки. Алгоритмы «простых включений», «простого выбора», «пузырька». Оценка числа операций (без правок).](https://www.notion.so/dc6b7bb9e6144c27b6c50880b8f9fb12)
    - [Понятие сортировки. Сортировка слиянием. Оценка числа операций (не из билетов).](#Сортировка-слиянием)
- Компрессия данных
    - [Метод Хаффмана построения оптимального префиксного двоичного кода.](#Метод-Хаффмана)
- Структуры данных
    - [Список как линейно упорядоченная структура данных последовательного доступа. Одно- и двусвязные списки. Алгоритмы поиска, вставки и удаления элемента.](#Списки-и-операции-над-ними)

____

## Быстрая сортировка Хоара

Постановка проблемы: есть набор неотсортированных данных. Необходимо произвести сортировку по возрастанию/убыванию, то есть произвести упорядочивание однотипных элементов.

Отличительной особенностью быстрой сортировки является **операция разбиения массива на две части относительно опорного элемента**. Например, если последовательность требуется упорядочить по возрастанию (наш случай в разборе), то в левую часть будут помещены все элементы, значения которых меньше значения опорного элемента, а в правую элементы, чьи значения больше или равны опорному. Если длина какой-то из получившихся в результате разбиения частей превышает один элемент, то для нее нужно **рекурсивно выполнить упорядочивание**, т. е. повторно запустить алгоритм на каждом из отрезков.

**Выбор опорного элемента** не влияет на результат, и поэтому может пасть на произвольный элемент. Тем не менее, **наибольшая эффективность** алгоритма достигается при выборе опорного элемента, делящего последовательность на равные или примерно равные части.

Непосредственно **сам  алгоритм:**

1. Выбираем опорный элемент *v* - как правило, берут середину рассматриваемого отрезка
2. Разбиваем массив на 3 части:
    - Создаём переменные *i* и *j* — индексы соответственно начала и конца рассматриваемого подмассива
    - Увеличиваем *i*, пока *i*-й элемент меньше опорного
    - Уменьшаем *j*, пока *j*-й элемент больше опорного
    - Если *i* всё ещё меньше *j*, то меняем *i*-й и *j*-й элементы местами, инкрементируем *i* и декрементируем *j*
    - Если *i* вдруг становится больше либо равно *j*, то прерываем цикл
3. В конце концов, просмотры слева-направо и справа-налево сходятся в одной точке *j*, которая нам разделит рассматриваемый массив на два подмассива. Повторяем рекурсивно алгоритм уже для них, пока не дойдём до массива из 1 элемента - это контролируется условием *if l < r* в основной функции *quicksort*.

```c
int partition(int a[], int l, int r) {
    int v = a[(l + r) / 2];
    int i = l;
    int j = r;
    while (i <= j) {
        while (a[i] < v) {
            i++;
	}
        while (a[j] > v) {
            j--;
	}
        if (i >= j) {
            break;
	}
        swap(a[i++], a[j--]);
    }
    return j;
}

void quicksort(int a[], int l, int r) {
    if (l < r) {
        int q = partition(a, l, r);
        quicksort(a, l, q);
        quicksort(a, q + 1, r);
    }
}
```

Для сортировки всего массива необходимо выполнить процедуру

```c
quicksort(a, 0, length(a) − 1)
```

**Оценка сложности алгоритма**:

Каждое **разделение** требует *O(n)* операций - в силу того, что мы идем слева-направо и справа-налево, пробегая все элементы текущего отрезка. **Количество шагов** деления (глубина рекурсии) составляет приблизительно *log n*, если массив делится на более-менее равные части. Таким образом, **общее быстродействие**: *O(n log n)*, что и имеет место на практике.

**Однако, возможен случай** таких входных данных, на которых алгоритм будет работать за *O(n^2)* операций. Такое происходит, если каждый раз в качестве опорного элемента выбирается максимум или минимум входной последовательности. В таком случае у нас всё время массив длины *N* будет делиться на два подмассива длины *1* и *N - 1*.

[:arrow_up: Back to contents](#Contents)
____

## Пирамидальная сортировка

Постановка проблемы: есть набор неотсортированных данных. Необходимо произвести сортировку по возрастанию/убыванию, то есть произвести упорядочивание однотипных элементов.

**Пирамидальная сортировка** (*HeapSort*) — это метод сортировки сравнением, основанный на такой структуре данных как двоичная куча.

Сам алгоритм можно разделить на два этапа:
1. Формирование двоичной кучи.
2. Сортировка данных на основе сформированной двоичной кучи.

Перед тем, как определить понятие бинарной кучи, необходимо понять, что называют законченным бинарным деревом. Итак, **законченное бинарное дерево** - это двоичное дерево, в котором **каждый уровень, за исключением, возможно, последнего, имеет полный набор узлов, и все листья расположены как можно левее.** Пример:
![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2a9a725e-8b17-4164-a23d-6bd5f49a057f/Untitled.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2a9a725e-8b17-4164-a23d-6bd5f49a057f/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200809%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20200809T111132Z&X-Amz-Expires=86400&X-Amz-Signature=5a0a0da93be296ddd2387b919494f6f3a68eab45cf9806058ba55a954d92b297&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)
Теперь можно сказать, что такое **двоичная куча** — это **законченное двоичное дерево**, в котором элементы хранятся в особом порядке: **значение в родительском узле больше (или меньше) значений в его двух дочерних узлах.** Первый вариант называется max-heap, а второй — min-heap. Другими словами, выполняется условие:

```c
// Для max-heap

a[i] >= a[2 * i + 1];
a[i] >= a[2 * i + 2];

индекс i - родитель
индекс 2i + 1 - левый ребенок
индекс 2i + 2 - правый ребенок
```

Будем хранить данные в виде обычного **массива**. Именно в таком виде представления данных будет удобно работать с индексами элементов (см. в коде). Далее в разборе мы будем рассматривать случай сортировки массива по возврастанию. 
Итак, пусть у нас дан массив *arr[]*, который нужно отсортировать. Длина массива - *n*.
#### Первый шаг: построение бинарной кучи.
Нужно построить бинарную кучу. Делать мы это будем следующим образом:
1. **Смотрим на сыновей слева и справа** - в массиве это *arr[2i+1]* и *arr[2i+2]* - выбираем наибольшего из сыновей и родителя, с которого мы начинали данный шаг.
2.  Если этот элемент больше родителя *arr[i]* - **меняем** его с *arr[i]* местами и идем к шагу 1, имея в виду новое положение *arr[i]* в массиве - **будем преобразовать затронутое поддерево. Иначе конец процедуры.**

```c
void heapify(int arr[], int n, int i) {
  int largest = i;
  // Инициализируем наибольший элемент как корень
  int l = 2*i + 1; // левый 
  int r = 2*i + 2; // правый

 // Если левый дочерний элемент больше корня
  if (l < n && arr[l] > arr[largest]) {
        largest = l;
	}

  // Если правый дочерний элемент больше, чем самый большой элемент на данный момент
  if (r < n && arr[r] > arr[largest]) {
        largest = r;
	}

  // Если самый большой элемент не корень
  if (largest != i) {
        swap(arr[i], arr[largest]);
	// Рекурсивно преобразуем в двоичную кучу затронутое поддерево
        heapify(arr, n, largest);
    }
}
```
Описанные выше два пункта выполняются для одного корня с индексом *i*, а не для всего массива. Поэтому **такую процедуру необходимо произвести с индекса *(n / 2) - 1* и до нуля.**

#### Второй шаг: непосредственно пирамидальная сортировка.
На данном этапе после приведения данных к двоичной куче **самый большой элемент хранится в корне кучи** (см. главное свойство бинарной кучи).
Основное тело алгоритма пирамидальной сортировки состоит из следующих пунктов:
1. **Будем менять элемент в корне кучи на последний элемент кучи, уменьшая после обмена её размер на единицу** - так мы будем отсекать те элементы, которые уже заняли нужные места и более сортировке не подлежат.
2. После такой замены **свойство бинарной кучи может нарушиться** - необходимо заново **преобразовать полученное бинарное дерево в max-heap с новым корнем**. Для этого будем вызывать ту же функцию *heapfy()*, которой мы пользовались при построении бинарной кучи, для корневого элемента.
3. Так будем выполнять, **пока индекс** нашей условной правой границы, которая с каждым шагом движется левее на одну позицию, **не станет меньше нуля** - это будет означать, что мы рассмотрели все элементы массива и сортировка окончена.

```c
// Основная функция, выполняющая пирамидальную сортировку
void heapSort(int arr[], int n) {
  // Построение кучи
  for (int i = n / 2 - 1; i >= 0; i--) {
      heapify(arr, n, i);
  }

 // Один за другим извлекаем элементы из кучи
  for (int i= n - 1; i >= 0; i--) {
      // Перемещаем текущий корень в конец
      swap(arr[0], arr[i]);

      // вызываем процедуру heapify на уменьшенной куче
      heapify(arr, i, 0);
  }
}
```

Иллюстрация: [Click on](https://www.youtube.com/watch?v=MtQL_ll5KhQ)

**Оценка:**
Самое **главное преимущество** данного алгоритма: число итераций цикла в процедуре просеивания *heapfy()* не превосходит высоты пирамиды, а высота полного бинарного дерева из *n* узлов, коим является пирамида, равна *log2(n)*.

Далее, просеивание имеет логарифмическую сложность. Это так, потому что мы в основном теле прошлись по всем элементам массива, применив к нему *heapfy()*, имеющую логарифмическую зависимость, и *swap()*, работающий за константное время - итого имеем *O(n * log2(n))*.

**Замечания:** несомненным достоинством данного алгоритма является то, что **худший, средний и лучший случаи для него совпадают.** Однако, сам является **неустойчивым**, то есть он допускает изменение относительного порядка сортируемых элементов.

[:arrow_up: Back to contents](#Contents)
____

## Сортировка слиянием

Постановка проблемы: есть набор неотсортированных данных. Необходимо произвести сортировку по возрастанию/убыванию, то есть произвести упорядочивание однотипных элементов.
Сортировка слиянием пригодится для таких структур данных, в которых доступ к элементам осуществляется последовательно (например, для потоков). Общая идея: **массив разбивается на две примерно равные части** и каждая из них **сортируется по отдельности**. Затем два отсортированных **подмассива сливаются в один**. Опишем процесс более детально - для этого разобьем весь алгоритм на следующие шаги:
1. Массив рекурсивно разбивается пополам, и каждая из половин делится до тех пор, пока размер очередного подмассива не станет равным единице
2. Далее выполняется операция алгоритма, называемая слиянием: два единичных массива сливаются в общий результирующий массив, при этом из каждого выбирается меньший элемент (для сортировки по возрастанию) и записывается в свободную левую ячейку результирующего массива. После чего из двух результирующих массивов собирается третий общий отсортированный массив, и так далее. В случае если один из массивов закончится, элементы другого дописываются в собираемый массив
3. В конце операции слияния элементы перезаписываются из результирующего массива в исходный.

Замечание: мы будем использовать **метод нисходящего слияния**. Алгоритм сортировки слияния допускает и другие методы (подробнее см. самостоятельно).
Рассмотрим его выполнение на примере: 
![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2a9a725e-8b17-4164-a23d-6bd5f49a057f/Untitled.png](http://selkie.macalester.edu/csinparallel/modules/MPIProgramming/build/html/_images/mergeSort.png)

Массив был разделен на единичные массивы, которые алгоритм сливает попарно до тех пор, пока не получится один массив, все элементы которого стоят на своих позициях.

Непосредственно сама реализация алгоритма:
```c

/* 
values[] - массив, поданный на вход
buffer[] - вспомогательный массив
l - левая граница (при начальном вызове l = 0)
r - правая граница (при начальном вызове r = values.size() - 1)
*/

void MergeSortImpl(int values[], int buffer[], int l, int r) {
  if (l < r) {
    // Выбираем индекс, указывающий на серединный элемент
    int m = (l + r) / 2;
    // Сортируем левую часть
    MergeSortImpl(values, buffer, l, m);
    // Сортируем правую часть
    MergeSortImpl(values, buffer, m + 1, r);

    // Выполняем непосредственно процедуру слияния	
    
    int k = l;
    
    /*
    i - индекс первого подмассива, который заканчивается на m - отсюда и условие (i <= m)
    j - индекс второго подмассива, который начинается с m и заканчивается на правой границе - отсюда и условие (j <= r)
    */
    for (int i = l, j = m + 1; i <= m || j <= r; ) {
     
      /* 
      Выбираем наименьший элемент среди двух подмассивов
      Или если в одном подмассиве элементы закончились, а во втором ещё нет,
      То скопируем все оставшиеся элементы в конец строющегося отсортированного массива (условие j > r)
      */
      if (j > r || (i <= m && values[i] < values[j])) {
        buffer[k] = values[i];
        ++i;
      } else {
        buffer[k] = values[j];
        ++j;
      }
      ++k;
    }
    
    // Копируем отсортированную часть в исходный массив values[]
    for (int i = l; i <= r; ++i) {
      values[i] = buffer[i];
    }
  }
}

void MergeSort(int values[], size_t len) {
  if (len != 0) {
    // Создаем вспомогательный массив
    int buffer[len];
    // Вызываем реализацию сортировки слиянием
    MergeSortImpl(values, buffer, 0, len - 1);
  }
}
```

**Оценка:**
Сортировка слиянием — хороший пример использования принципа «разделяй и властвуй». На каждом шаге мы уменьшаем размер рассматриваемого массива вдвое, доходя до массива, состоящего из одного элемента. Заметим сразу, что мы использовали *O(n)* вспомогательной памяти - этот факт относят к главным недостаткам данного алгоритма. Однако, он является устойчивым, т.е. сохраняет порядок равных элементов, а также у него совпадает худшее, среднее и лучшее время работы - *O(n * log2(n))*.

[:arrow_up: Back to contents](#Contents)
____
____
____

## Метод Хаффмана

Дадим сначала некоторые определения, чтобы мы с вами говорили на одном языке. **Алфавитом** называется конечное множество символов, а **сообщением** называется конечная последовательность символов. Множество всех сообщений алфавита _А_ будем обозначать за _А*_.
Теперь затронем тему кодирования. **Кодом** мы будем называть отображение _K: A* -> B*_ такое, что _K(c1 c2 ... cN) = K(c1)K(c2) ... K(cN)_ для любого сообщения _c1 c2 ... cN_ из _А*_. Другими словами, код есть сопоставление любому сообщению (к примеру, обычному слову из русского алфавита), составленному из символов алфавита _А_ (прим. русские буквы) другое сообщение, но составленного уже из символов алфавита _B_, причем это сопоставление происходит **поэлементно**. Обычно говорят, что алфавит _А_ есть исходный алфавит, а _B_ - конечный. При этом если конечный алфавит состоит всего из двух символов 0 и 1, то код будет называться **двоичным**.
Далее, код называется **префиксным**, если ни одно кодовое слово не является началом (префиксом) никакого другого кодового слова. Исходя из определения сразу можно обозначить следствия:
- В дереве префиксного кода коды всех символов заканчиваются в листьях
- Префиксный код позволяет выделять коды символов без использования разделителей
- Префиксный код декодируется однозначно.

Метод Хаффмана оперирует с **оптимальными двоичными кодами**. Не каждый код, естественно, будет оптимальным. Заметим сразу, что оптимальный двоичный код не обязательно уникален для данного текста. Забегая вперед, в этом случае можно будет выбрать любой такой код. Что мы будем понимать под оптимальным (не только двоичным) кодом? Представим, что у нас есть некоторый текст. Мы для каждого символа, встречающегося в тексте, посчитаем количество его вхождений. Далее, построим код для данного текста. Код - это также некоторый текст, у которого мы можем посчитать его длину - сделаем это. В итоге получим число _N_, равное количеству символов закодированного текста. Так вот, оптимальный код - это такой код, у которого для данного текста число _N_ минимально, т. е. мы всегда будем стремиться к тому, чтобы максимально сократить длину текста после кодирования.
Перейдем к самой главной части - алгоритм Хаффмана построения оптимального двоичного дерева.
Установим сначала, что **дерево кодирования Хаффмана** - это двоичное дерево, у которого каждый узел имеет **вес**, и при этом вес родителя равен суммарному весу его детей. **Алгоритм построения дерева кодирования Хаффмана** таков:

1. Буквы входного алфавита образуют список свободных узлов будущего дерева кодирования. Каждый узел в этом списке имеет вес, равный вероятности появления соответствующей буквы в сообщении. Для работы только с целыми значениями можно хранить не вероятность, а количество вхождений данного символа в сообщение.
2. Выбираются два свободных узла дерева с наименьшими весами. Если имеется более двух свободных узлов с наименьшими весами, то можно брать любую пару.
3. Создается их родитель с весом, равным их суммарному весу.
4. Родитель добавляется в список свободных узлов, а двое его детей удаляются из этого списка.
5. Одной дуге, выходящей из узла-родителя, ставится в соответствие бит 1, другой - 0.
6. Пункты 2, 3, 4, 5 повторяются до тех пор, пока в списке свободных узлов не останется только один узел. Этот узел будет являться корнем дерева. Его вес получается равным единице - суммарной вероятности всех букв сообщения (или, соответственно, количеству всех символов в исходном сообщении).

Двигаясь по кодовому дереву сверху вниз и последовательно выписывая двоичные цифры, соответствующие дугам, можно получить **коды букв входного алфавита**.
Рассмотрим отличный [**пример с Хабра**](https://habr.com/ru/post/144200/):

Исходная строка "beep boop beer!". Строим таблицу частот:

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6dd361be-275f-4a51-9ce1-03d9441618f7/Untitled.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6dd361be-275f-4a51-9ce1-03d9441618f7/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200809%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20200809T164210Z&X-Amz-Expires=86400&X-Amz-Signature=24504eef36be3ea84fcc9cfccf7eff1b2dc9d46b72026acbe7dfa5acc32047e2&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/10c74467-47ed-4e98-971d-f886af55b935/Untitled.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/10c74467-47ed-4e98-971d-f886af55b935/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200809%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20200809T164246Z&X-Amz-Expires=86400&X-Amz-Signature=464361811a143934671b6ea5734d94d704b1d9ac894507478739102a45fe20ac&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5a03b379-9f6c-4ce4-9466-25c60033893a/Untitled.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5a03b379-9f6c-4ce4-9466-25c60033893a/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200809%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20200809T164259Z&X-Amz-Expires=86400&X-Amz-Signature=df26ae74c453bbedff9f99faf8a0a4032e83ca8cf26624ecd5818fad62d1b697&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/116bd066-b16c-4bdb-932c-48eb801f4799/Untitled.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/116bd066-b16c-4bdb-932c-48eb801f4799/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200809%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20200809T164309Z&X-Amz-Expires=86400&X-Amz-Signature=3bc164fe07aed46350c7fed3ef53a787fa24f9225e33fd505c6dc292df38fc61&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

Далее, запустив алгоритм поиска в глубину (DFS), мы сможем для каждого символа легко восстановить его новый двоичный код.

С помощью полученных двоичных кодов мы можем закодировать наш текст, который после перевода в байты (возможно, придется добавить недостающие биты) будет, как правило, занимать меньше места. Рекомендую поэкспериментировать с маленькими текстами и лично убедиться, что после применения метода Хаффмана ваш текст только разрастется в размерах.

Засчет данного алгоритма работают несколько известных архиваторов (см. Википедию).

[:arrow_up: Back to contents](#Contents)
____
____
____

## Списки и операции над ними

**Связный список** (англ. List) — это структура данных, состоящая из элементов, содержащих помимо собственных данных ссылки на следующий и/или предыдущий элемент списка. С помощью списков можно реализовать такие структуры данных как стек и очередь.

В основе связного списка лежит понятие узла, или элемента (Node). **Узел** — это контейнер, который позволяет хранить данные и получать следующий узел с помощью указателя.

Списки бывают **односвязные** (элементы содержат указатель только на следующий элемент) и **двусвязные** (элементы содержат указатели как на следующий, так и на предыдущий, благодаря чему становится проще удалять и переставлять элементы). Ещё хочется добавить, что бывают **циклические списки** - в них первый элемент является следующим для последнего элемента списка:

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/fe4454b9-7ed9-484a-85c0-0ceee5ae84db/Untitled.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/fe4454b9-7ed9-484a-85c0-0ceee5ae84db/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200810%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20200810T043912Z&X-Amz-Expires=86400&X-Amz-Signature=0518f078184d073106d64d32454190b4e62cf6a2fc6c463b330bec32f5d3b83e&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

Существует также улучшенная реализация списка: **развёрнутый связный список** - по своей сути это связный список, где каждый элемент содержит небольшой массив _N_ элементов. Таким образом мы выигрываем и в памяти, так как в списке из _M_ элементов не _M_ ссылок, а _M/N_ (в силу того, что в каждом блоке хранятся по _N_ элементов, значит ссылок всего нужно будет _M/N_), и в производительности - так как доступ к данным, хранящихся в массиве, быстрее, чем переход по ссылке + получение поля data. Пример устройства с [Википедии](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D0%B2%D1%91%D1%80%D0%BD%D1%83%D1%82%D1%8B%D0%B9_%D1%81%D0%B2%D1%8F%D0%B7%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D0%B8%D1%81%D0%BE%D0%BA):

![https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Unrolled_linked_lists_%281-8%29.PNG/220px-Unrolled_linked_lists_%281-8%29.PNG](https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Unrolled_linked_lists_%281-8%29.PNG/220px-Unrolled_linked_lists_%281-8%29.PNG)

Список задается в Си следующим образом:
```c
// A linked list node 
struct Node {
  T data; 
  struct Node *next; 
};
```

**Базовые операции над списками:**

- **Вставка**

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7d1c138a-29af-4300-8687-5c7747bfa3ec/Untitled.png](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7d1c138a-29af-4300-8687-5c7747bfa3ec/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200810%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20200810T044648Z&X-Amz-Expires=86400&X-Amz-Signature=557c675de10802edb1a94bebe065121b0ad4f0d90413ecd4b3edb5f1e14dd56c&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22)

Функция вставки:
```c
// lst - это указатель на блок, ПОСЛЕ которого мы хотим добавить новый
// Возвращает указатель на добавленный блок

struct Node* addElementToLinkedList(struct Node *lst, T newData) {
  struct Node *newNode, *p;
  newNode = malloc(sizeof(struct Node));
  p = lst->next; // сохранение указателя на следующий узел
  lst->next = newNode; // предыдущий узел указывает на создаваемый
  newNode->data = newData; // сохранение поля данных добавляемого узла
  newNode->next = p; // созданный узел указывает на следующий элемент
  return newNode;
}
```
- **Удаление**

Функция удаляет первый элемент списка со значением, равным переданному, или конкрентый узел, если мы точно знаем, какой из мы хотим удалить. На практике бывает, что она возвращает _true_, если элемент был удален, и _false_ в противном случае, но чаще возвращает указатель на узел, предыдущий за удаляемым. В реализации мы так и поступим. Теперь непосредственно сам алгоритм:
1. Найти узел, который необходимо удалить;
2. Изменить значение поля _Next_ предыдущего узла так, чтобы оно указывало на узел, следующий за удаляемым;
3. Удалить узел с помощью встроенной в Си функции _free()_.

Реализация:
```c
struct Node *deleteElementFromLinkedList(struct Node *lst, struct Node *root) {
  struct Node *temp;
  temp = root;
  // просматриваем список, начиная с корня,
  // пока не найдем узел, предшествующий lst
  while (temp->next != lst) { 
    temp = temp->next;
  }
  temp->next = lst->next; // переставляем указатель
  free(lst); // освобождаем память удаляемого узла
  return temp;
}
```
- **Поиск**

Рассмотрим метод _Contains_. Он достаточно простой. Метод просматривает каждый элемент списка, от первого до последнего, и возвращает _true_ как только найдет узел, значение которого равно переданному параметру. Если такой узел не найден и метод дошел до конца списка, то возвращается _false_.
Реализация:
```c
bool Contains(struct Node *root, T data) {
  while (root != NULL) {
    if (data == root->data) {
      return true;		
    }
      root = root->next;
  }
  return false;
}
```
Можно условиться, что функция будет возвращать _-1_ в качестве _false_ и индекс найденного элемента в списке в противном случае - как один из вариантов улучшения метода. Возможно будет выгоднее вернуть сам узел, чтобы вне функции можно было с ним работать.

Немного про асимптотику данных операций:
| Алгоритм | Среднее значение | Худший случай |
|:-----------------------:|:---------:|:---------:|
| Вставка | O(1) | O(1) |
| Удаление | O(n) | O(n) |
| Поиск | O(n) | O(n) |

[:arrow_up: Back to contents](#Contents)
____
